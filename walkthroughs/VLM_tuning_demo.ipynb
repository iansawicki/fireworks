{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iansawicki/fireworks/blob/main/walkthroughs/VLM_tuning_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Supervised VLM Fine-Tuning on Fireworks\n",
        "\n",
        "This notebook demonstrates the **Fireworks CLI commands** for fine-tuning with minimal Python wrapper code.\n",
        "\n",
        "## üìã Table of Contents\n",
        "\n",
        "| Section | Description | Key CLI Commands |\n",
        "|---------|-------------|------------------|\n",
        "| **0. Setup** | Install dependencies and environment | - |\n",
        "| **1. Authentication** | Setup CLI and verify credentials | `firectl signin`, `firectl whoami` |\n",
        "| **2. Dataset Preparation** | Load and convert Spider dataset | - |\n",
        "| **3. Dataset Upload** | Upload to Fireworks (Local + GCS) | `firectl create dataset` |\n",
        "| **4. Fine-tuning** | Create and monitor training job | `firectl create supervised-fine-tuning-job` |\n",
        "| **5. Deployment** | Deploy trained model | `firectl create deployment` |\n",
        "| **6. Testing** | Query your deployed model | `curl` + Python requests |\n",
        "\n",
        "## üéØ What You'll Learn\n",
        "\n",
        "- **CLI Commands**: The exact `firectl` commands to run\n",
        "- **End-to-End Workflow**: From dataset to deployed model  \n",
        "- **Two Approaches**: Local files vs. Google Cloud Storage\n",
        "- **Best Practices**: Dataset formats, fine-tuning parameters, testing\n",
        "\n",
        "## üìã Prerequisites\n",
        "\n",
        "1. **Fireworks AI Account**: Sign up at [fireworks.ai](https://fireworks.ai)\n",
        "2. **Fireworks CLI (mac)**: `brew tap fw-ai/firectl && brew install firectl`\n",
        "3. **API Key**: `export FIREWORKS_API_KEY='your-key'`\n",
        "4. **Optional**: HuggingFace token for private datasets\n",
        "\n",
        "## üöÄ Quick Start\n",
        "\n",
        "If you just want the commands, here's the complete workflow:\n",
        "\n",
        "```bash\n",
        "# 1. Setup\n",
        "export FIREWORKS_API_KEY='your-key'\n",
        "firectl signin\n",
        "\n",
        "# 2. Upload dataset (choose one)\n",
        "firectl create dataset my-dataset ./data.jsonl                    # Local file\n",
        "firectl create dataset my-dataset --external-url gs://bucket/data.jsonl  # GCS\n",
        "\n",
        "# 3. Start fine-tuning\n",
        "firectl create supervised-fine-tuning-job \\\n",
        "  --dataset my-dataset --output-model my-model \\\n",
        "  --base-model accounts/fireworks/models/qwen2p5-coder-32b-instruct \\\n",
        "  --epochs 3 --turbo --early-stop --eval-auto-carveout\n",
        "\n",
        "# 4. Monitor and deploy\n",
        "firectl get supervised-fine-tuning-job JOB_ID\n",
        "firectl create deployment accounts/ACCOUNT/models/my-model --enable-addons\n",
        "```"
      ],
      "metadata": {
        "id": "X0JMxbjNdPX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install jsonlines\n",
        "!wget -O firectl.gz https://storage.googleapis.com/fireworks-public/firectl/stable/linux-amd64.gz\n",
        "!gunzip firectl.gz\n",
        "!sudo install -o root -g root -m 0755 firectl /usr/local/bin/firectl\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1UgPgBheUR02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Authentication & Environment Setup\n",
        "\n",
        "## üìã Section Overview\n",
        "- Install Fireworks CLI\n",
        "- Set API key and authenticate\n",
        "- Verify setup with Python\n",
        "- Optional: Setup HuggingFace access\n",
        "\n",
        "## üîß Required CLI Commands\n",
        "\n",
        "Run these commands in your terminal **before** running this notebook:\n",
        "\n",
        "```bash\n",
        "# 1. Install Fireworks CLI (on mac)\n",
        "brew tap fw-ai/firectl && brew install firectl\n",
        "\n",
        "# 1.2 Or Linux (If you're using Collab, do this in the terminal.)\n",
        "wget -O firectl.gz https://storage.googleapis.com/fireworks-public/firectl/stable/linux-amd64.gz\n",
        "gunzip firectl.gz\n",
        "sudo install -o root -g root -m 0755 firectl /usr/local/bin/firectl\n",
        "\n",
        "# 2. Set your API key\n",
        "export FIREWORKS_API_KEY='your-api-key-here'\n",
        "\n",
        "# 3. Sign into Fireworks\n",
        "firectl signin\n",
        "\n",
        "# 4. Verify authentication\n",
        "firectl whoami\n",
        "\n",
        "# 5. Set your HF API key\n",
        "```\n",
        "\n",
        "**Important**: The Python code below will check if these steps were completed successfully."
      ],
      "metadata": {
        "id": "bHmMXLt-dudf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Securely input API key and sign in\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# Get API key securely\n",
        "api_key = getpass.getpass(\"Enter your Fireworks API key: \")\n",
        "\n",
        "# Set and use in one go\n",
        "os.environ['FIREWORKS_API_KEY'] = api_key\n",
        "!firectl signin\n",
        "\n",
        "# Check Prerequisites\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "print(\"üîß Checking Prerequisites...\")\n",
        "\n",
        "# Check API key\n",
        "if api_key:\n",
        "    print(f\"‚úÖ API Key found: {api_key[:10]}...\")\n",
        "else:\n",
        "    print(\"‚ùå No FIREWORKS_API_KEY found\")\n",
        "    print(\"üí° Set it with: export FIREWORKS_API_KEY='your-key'\")\n",
        "\n",
        "# Check firectl\n",
        "try:\n",
        "    result = subprocess.run([\"firectl\", \"version\"], capture_output=True, text=True)\n",
        "    if result.returncode == 0:\n",
        "        print(f\"‚úÖ firectl installed: {result.stdout.strip()}\")\n",
        "    else:\n",
        "        print(\"‚ùå firectl not working\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå firectl not found\")\n",
        "    print(\"üí° Install with: brew tap fw-ai/firectl && brew install firectl\")\n",
        "\n",
        "# Check if signed in\n",
        "try:\n",
        "    result = subprocess.run([\"firectl\", \"whoami\"], capture_output=True, text=True)\n",
        "    if result.returncode == 0:\n",
        "        print(\"‚úÖ Signed into Fireworks CLI\")\n",
        "        print(result.stdout.strip())\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Not signed into Fireworks CLI\")\n",
        "        print(\"üí° Sign in with: firectl signin\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è  Could not check Fireworks CLI status\")\n",
        "\n",
        "print(\"üöÄ Prerequisites check complete!\")\n"
      ],
      "metadata": {
        "id": "T55aPgzOdt8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Dataset from Hugging Face\n",
        "\n",
        "We'll be loading the PubTabNet dataset from Hugging Face, which provides a convenient way to access the data without dealing with large downloads."
      ],
      "metadata": {
        "id": "JyTHM_T4XGz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing prerequisites\n",
        "import sys\n",
        "import requests\n",
        "import tarfile\n",
        "import jsonlines\n",
        "import numpy as np\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from PIL import ImageFont, ImageDraw\n",
        "from glob import glob\n",
        "from matplotlib import pyplot as plt\n",
        "from datasets import load_dataset\n",
        "%matplotlib inline\n",
        "\n",
        "# Load only a subset of the PubTabNet dataset from Hugging Face\n",
        "print(\"Loading a subset of PubTabNet dataset from Hugging Face...\")\n",
        "\n",
        "# # Option 1: Load first 1000 examples from train split (most efficient)\n",
        "# ds = load_dataset(\"apoidea/pubtabnet-html\", split=\"train[:1000]\")\n",
        "# print(f\"Loaded {len(ds)} examples from the train split\")\n",
        "\n",
        "# Option 2: If you want a specific range (e.g., examples 1000-2000)\n",
        "# ds = load_dataset(\"apoidea/pubtabnet-html\", split=\"train[1000:2000]\")\n",
        "\n",
        "# Option 3: For a percentage of the data (e.g., first 10%)\n",
        "# ds = load_dataset(\"apoidea/pubtabnet-html\", split=\"train[:10%]\")\n",
        "\n",
        "# Option 4: For multiple splits with subsets\n",
        "ds = load_dataset(\"apoidea/pubtabnet-html\", split={\n",
        "    \"train\": \"train[:800]\",     # first 800 for training\n",
        "    \"test\": \"train[800:1000]\"   # next 200 for testing\n",
        "})\n",
        "\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Dataset type: {type(ds)}\")\n",
        "print(f\"Number of examples: {len(ds)}\")\n",
        "print(f\"Columns: {ds.column_names}\")"
      ],
      "metadata": {
        "id": "lMW8E6NUTnOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For easier access, extract just the train split\n",
        "ds_train = ds['train']\n",
        "ds_test = ds['test']\n",
        "\n",
        "print(f\"Train dataset: {len(ds_train)} examples\")\n",
        "print(f\"Test dataset: {len(ds_test)} examples\")\n",
        "\n",
        "# Look at the first 5 examples\n",
        "print(f\"\\nFirst 5 examples:\")\n",
        "for i in range(5):\n",
        "    example = ds_train[i]\n",
        "    print(f\"\\n--- Example {i+1} ---\")\n",
        "    for key, value in example.items():\n",
        "        if isinstance(value, str) and len(value) > 100:\n",
        "            print(f\"  {key}: {value[:100]}...\")\n",
        "        elif key == 'image':\n",
        "            print(f\"  {key}: <PIL Image object>\")\n",
        "        else:\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "# Create sample for detailed exploration\n",
        "sample_data = ds_train.select(range(5))\n",
        "print(f\"\\nSelected {len(sample_data)} examples for detailed exploration\")\n",
        "\n",
        "# Display the first 5 images in a clean 2x3 grid layout\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()  # Flatten to make indexing easier\n",
        "\n",
        "for i in range(5):\n",
        "    img_example = ds_train[i]\n",
        "    axes[i].imshow(img_example['image'])\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title(f\"Image {i+1}: {img_example['imgid']}\", fontsize=12, pad=10)\n",
        "\n",
        "# Hide the 6th subplot since we only have 5 images\n",
        "axes[5].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7M9SMq2BYoOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Dataset Upload to Fireworks\n",
        "\n",
        "## üìã Section Overview\n",
        "- Convert data to Chat Completions format (required by Fireworks)\n",
        "- Create JSONL files for upload\n",
        "- Upload using `firectl create dataset` command\n",
        "- Show both local file and GCS upload methods\n",
        "\n",
        "## üîÑ Convert to Chat Completions Format\n",
        "\n",
        "Fireworks requires data in Chat Completions format with `system`, `user`, and `assistant` messages.\n",
        "\n",
        "### Dataset Requirements:\n",
        "- Format: .jsonl file\n",
        "- Minimum examples: 3\n",
        "- Maximum examples: 3 million per dataset\n",
        "- Images: Must be base64 encoded with proper MIME type prefixes\n",
        "- Supported image formats: PNG, JPG, JPEG\n",
        "\n",
        "- Message Schema: Each training example must include a messages array where each message has:\n",
        "- role: one of system, user, or assistant\n",
        "- content: an array containing text and image objects or just text"
      ],
      "metadata": {
        "id": "GzW8mep8glLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert image to base64 format, and generate jsonl file\n",
        "In this case we will ask 2 questions per image"
      ],
      "metadata": {
        "id": "20GQhV5ATGOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combined: Convert images to base64, create JSONL file, and display first example\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def pil_to_base64(pil_image):\n",
        "    \"\"\"Convert PIL Image to base64 string\"\"\"\n",
        "    buffered = BytesIO()\n",
        "    pil_image.save(buffered, format=\"PNG\")\n",
        "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "    return f\"data:image/png;base64,{img_str}\"\n",
        "\n",
        "def create_table_qa_jsonl_single(base64_data, output_file=\"pubtabnet_table_qa.jsonl\"):\n",
        "    \"\"\"Create JSONL file with exactly ONE example per image\"\"\"\n",
        "\n",
        "    def extract_table_info(html_table):\n",
        "        \"\"\"Extract meaningful information from HTML table\"\"\"\n",
        "        try:\n",
        "            soup = BeautifulSoup(html_table, 'html.parser')\n",
        "            table = soup.find('table')\n",
        "            if not table:\n",
        "                return \"This appears to be a table with structured data.\"\n",
        "\n",
        "            rows = table.find_all('tr')\n",
        "            if not rows:\n",
        "                return \"This appears to be a table with structured data.\"\n",
        "\n",
        "            # Extract headers if available\n",
        "            headers = []\n",
        "            first_row = rows[0]\n",
        "            header_cells = first_row.find_all(['th', 'td'])\n",
        "            headers = [cell.get_text(strip=True) for cell in header_cells if cell.get_text(strip=True)]\n",
        "\n",
        "            # Count rows and columns\n",
        "            num_rows = len(rows)\n",
        "            num_cols = len(header_cells) if header_cells else 0\n",
        "\n",
        "            # Extract some sample data\n",
        "            sample_data = []\n",
        "            for row in rows[1:3]:  # Get first 2 data rows\n",
        "                cells = row.find_all(['td', 'th'])\n",
        "                row_data = [cell.get_text(strip=True) for cell in cells]\n",
        "                if any(row_data):  # Only add non-empty rows\n",
        "                    sample_data.append(row_data)\n",
        "\n",
        "            description = f\"This table has {num_rows} rows and {num_cols} columns.\"\n",
        "            if headers:\n",
        "                description += f\" The columns are: {', '.join(headers)}.\"\n",
        "\n",
        "            return description, headers, sample_data\n",
        "\n",
        "        except Exception as e:\n",
        "            return \"This appears to be a table with structured data.\", [], []\n",
        "\n",
        "    # Different question templates - pick ONE per image\n",
        "    question_templates = [\n",
        "        \"What information is shown in this table?\",\n",
        "        \"Describe the content and structure of this table.\",\n",
        "        \"What data does this table contain?\",\n",
        "        \"Can you analyze this table and tell me what it shows?\",\n",
        "        \"What are the main elements of this table?\",\n",
        "        \"Summarize the information presented in this table.\",\n",
        "        \"What can you tell me about the data in this table?\",\n",
        "        \"Describe what this table is displaying.\",\n",
        "    ]\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        for i, example in enumerate(base64_data):\n",
        "            # Extract information from the HTML table\n",
        "            description, headers, sample_data = extract_table_info(example['html_table'])\n",
        "\n",
        "            # Create a comprehensive response about the table content\n",
        "            response = description\n",
        "            if headers:\n",
        "                response += f\" The table includes columns for {', '.join(headers)}.\"\n",
        "            if sample_data:\n",
        "                response += \" Based on the visible data, this table contains structured information that can be queried and analyzed.\"\n",
        "\n",
        "            # Pick just ONE question per image\n",
        "            question = random.choice(question_templates)\n",
        "\n",
        "            training_example = {\n",
        "                \"messages\": [\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a helpful assistant that can analyze tables and documents to answer questions about their content. Focus on understanding what information is presented and be ready to answer specific questions about the data.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\n",
        "                                \"type\": \"image_url\",\n",
        "                                \"image_url\": {\n",
        "                                    \"url\": example['image_base64']\n",
        "                                }\n",
        "                            },\n",
        "                            {\n",
        "                                \"type\": \"text\",\n",
        "                                \"text\": question\n",
        "                            }\n",
        "                        ]\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": response\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            f.write(json.dumps(training_example) + '\\n')\n",
        "\n",
        "            if (i + 1) % 25 == 0:\n",
        "                print(f\"Processed {i + 1}/{len(base64_data)} examples...\")\n",
        "\n",
        "    print(f\"‚úì Created {output_file} with exactly {len(base64_data)} training examples\")\n",
        "    return output_file\n",
        "\n",
        "def show_jsonl_with_image_fixed(jsonl_file):\n",
        "    \"\"\"Display first line with truncated base64 AND show the actual image\"\"\"\n",
        "\n",
        "    with open(jsonl_file, 'r') as f:\n",
        "        first_line = f.readline().strip()\n",
        "\n",
        "    example = json.loads(first_line)\n",
        "\n",
        "    # Create a copy with truncated base64\n",
        "    example_copy = json.loads(json.dumps(example))  # Deep copy\n",
        "\n",
        "    # Find the image content item\n",
        "    image_content_item = None\n",
        "    image_index = None\n",
        "    for i, content in enumerate(example['messages'][1]['content']):\n",
        "        if content.get('type') == 'image_url':\n",
        "            image_content_item = content\n",
        "            image_index = i\n",
        "            break\n",
        "\n",
        "    if image_content_item is None:\n",
        "        print(\"ERROR: No image_url content found!\")\n",
        "        return\n",
        "\n",
        "    # Get the actual image URL\n",
        "    image_content = image_content_item['image_url']['url']\n",
        "\n",
        "    if ',' in image_content:\n",
        "        prefix, base64_data = image_content.split(',', 1)\n",
        "        truncated = f\"{prefix},{base64_data[:50]}...[TRUNCATED {len(base64_data)} total chars]\"\n",
        "        example_copy['messages'][1]['content'][image_index]['image_url']['url'] = truncated\n",
        "\n",
        "    # Show the JSON structure\n",
        "    pretty_json = json.dumps(example_copy, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"First JSONL example (with truncated base64):\")\n",
        "    print(\"=\" * 60)\n",
        "    print(pretty_json)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"CORRESPONDING IMAGE:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Convert base64 back to image and display\n",
        "    try:\n",
        "        # Extract and decode the base64 image\n",
        "        if ',' in image_content:\n",
        "            image_data = image_content.split(',')[1]\n",
        "        else:\n",
        "            image_data = image_content\n",
        "\n",
        "        # Decode base64 to image\n",
        "        image_bytes = base64.b64decode(image_data)\n",
        "        image = Image.open(BytesIO(image_bytes))\n",
        "\n",
        "        # Display using matplotlib\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.title(\"Table Image from JSONL Training Data\", fontsize=14, pad=20)\n",
        "        plt.show()\n",
        "\n",
        "        # Show details\n",
        "        print(f\"\\nImage details:\")\n",
        "        print(f\"Size: {image.size}\")\n",
        "        print(f\"Mode: {image.mode}\")\n",
        "        print(f\"Base64 length: {len(image_data)} characters\")\n",
        "\n",
        "        # Show the question and answer\n",
        "        text_content = None\n",
        "        for content in example['messages'][1]['content']:\n",
        "            if content.get('type') == 'text':\n",
        "                text_content = content.get('text')\n",
        "                break\n",
        "\n",
        "        print(f\"\\nTraining pair:\")\n",
        "        print(f\"Question: {text_content}\")\n",
        "        print(f\"Answer: {example['messages'][2]['content'][:300]}...\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error displaying image: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# ========== MAIN EXECUTION ==========\n",
        "\n",
        "print(\"üîÑ Step 1: Converting first 100 images to base64...\")\n",
        "\n",
        "# Get first 100 examples and convert images to base64\n",
        "ds_train = ds['train']\n",
        "first_100 = ds_train.select(range(100))\n",
        "\n",
        "# Create a list to store the converted data\n",
        "base64_data = []\n",
        "\n",
        "for i in range(100):\n",
        "    example = first_100[i]\n",
        "\n",
        "    # Convert PIL Image to base64\n",
        "    base64_image = pil_to_base64(example['image'])\n",
        "\n",
        "    # Create new example with base64 image\n",
        "    base64_example = {\n",
        "        'image_base64': base64_image,\n",
        "        'imgid': example['imgid'],\n",
        "        'split': example['split'],\n",
        "        'html': example['html'],\n",
        "        'html_table': example['html_table']\n",
        "    }\n",
        "\n",
        "    base64_data.append(base64_example)\n",
        "\n",
        "    if (i + 1) % 20 == 0:  # Progress indicator\n",
        "        print(f\"Converted {i + 1}/100 images...\")\n",
        "\n",
        "print(f\"‚úÖ Successfully converted {len(base64_data)} images to base64 format\")\n",
        "\n",
        "# Check the first example\n",
        "first_base64 = base64_data[0]\n",
        "print(f\"\\nFirst base64 example:\")\n",
        "print(f\"Image ID: {first_base64['imgid']}\")\n",
        "print(f\"Base64 length: {len(first_base64['image_base64'])}\")\n",
        "print(f\"Base64 preview: {first_base64['image_base64'][:100]}...\")\n",
        "\n",
        "print(f\"\\nüîÑ Step 2: Creating JSONL file for training...\")\n",
        "\n",
        "# Create the JSONL file with exactly 100 examples\n",
        "jsonl_file = create_table_qa_jsonl_single(base64_data)\n",
        "\n",
        "# Verify the count\n",
        "with open(jsonl_file, 'r') as f:\n",
        "    line_count = sum(1 for line in f)\n",
        "print(f\"Final verification: {line_count} examples in JSONL file\")\n",
        "\n",
        "print(f\"\\nüîÑ Step 3: Displaying first example...\")\n",
        "\n",
        "# Display the first example\n",
        "show_jsonl_with_image_fixed(jsonl_file)\n",
        "\n",
        "print(f\"\\n‚úÖ Complete! JSONL file '{jsonl_file}' is ready for upload to Fireworks AI\")"
      ],
      "metadata": {
        "id": "jc8goTyTe6Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì§ Upload Dataset - Local File Method\n",
        "\n",
        "Upload your JSONL file to Fireworks:\n",
        "\n",
        "```bash\n",
        "firectl create dataset DATASET_NAME ./your-file.jsonl\n",
        "```"
      ],
      "metadata": {
        "id": "pTSD1r7LDzFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Create timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# File paths (adjust these to match your actual files)\n",
        "sample_file = \"pubtabnet_table_qa.jsonl\"\n",
        "\n",
        "\n",
        "# Create unique dataset name\n",
        "dataset_name = f\"pubtabnet-table-qa-{timestamp}\"\n",
        "\n",
        "print(f\"üì§ Uploading dataset: {dataset_name}\")\n",
        "print(f\"üìÑ File: {sample_file}\")\n",
        "\n",
        "# Check if firectl exists and make it executable\n",
        "firectl_path = \"./firectl\"\n",
        "if os.path.exists(firectl_path):\n",
        "    # Make firectl executable\n",
        "    os.chmod(firectl_path, 0o755)\n",
        "    print(f\"‚úÖ Found firectl at {firectl_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå firectl not found at {firectl_path}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Check if the data file exists\n",
        "if not os.path.exists(sample_file):\n",
        "    print(f\"‚ùå Data file not found: {sample_file}\")\n",
        "    print(\"Available files:\")\n",
        "    for f in os.listdir(\".\"):\n",
        "        if f.endswith(\".jsonl\"):\n",
        "            print(f\"  - {f}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Build and run the command with full path to firectl\n",
        "cmd = [firectl_path, \"-a\", \"pyroworks\", \"create\", \"dataset\", dataset_name, sample_file]\n",
        "print(f\"üîß Running: {' '.join(cmd)}\")\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"‚úÖ Dataset upload successful!\")\n",
        "    print(result.stdout)\n",
        "    print(f\"üìä Dataset name: {dataset_name}\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"‚ùå Upload failed: {e}\")\n",
        "    print(f\"Error output: {e.stderr}\")\n",
        "    print(f\"Return code: {e.returncode}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå firectl binary not found or not executable.\")"
      ],
      "metadata": {
        "id": "YoOugpxAEM_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! firectl get dataset {dataset_name}"
      ],
      "metadata": {
        "id": "KvrVcOFhGAtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Create Fine-tuning Job\n",
        "\n",
        "## üìã Section Overview  \n",
        "- Create fine-tuning job with `firectl create supervised-fine-tuning-job`\n",
        "- Monitor training progress\n",
        "- Best practices for parameters\n",
        "\n",
        "## üöÄ Start Fine-tuning\n",
        "\n",
        "Here's the key CLI command to start training:\n",
        "\n",
        "```bash\n",
        "firectl create supervised-fine-tuning-job \\\n",
        "  --base-model accounts/fireworks/models/qwen2p5-vl-32b-instruct \\\n",
        "  --dataset DATASET_NAME \\\n",
        "  --output-model MODEL_NAME \\\n",
        "  --display-name \"pubtabnet-table-qa Fine-tune\" \\\n",
        "  --epochs 3 \\\n",
        "  --learning-rate 0.0001 \\\n",
        "  --turbo \\\n",
        "  --early-stop \\\n",
        "  --eval-auto-carveout\n",
        "```\n",
        "\n",
        "## üìä Parameter Guide\n",
        "\n",
        "| Parameter | Description | Recommended Value |\n",
        "|-----------|-------------|-------------------|\n",
        "| `--base-model` | Base model to fine-tune | `qwen2p5-vl-32b-instruct` |\n",
        "| `--dataset` | Your uploaded dataset ID | From step 3 |\n",
        "| `--output-model` | Name for your fine-tuned model | `my-pubtabnet-table-qa-model` |\n",
        "| `--epochs` | Training iterations | `3` (start small) |\n",
        "| `--learning-rate` | Learning rate | `0.0001` |\n",
        "| `--turbo` | Faster training | Always include |\n",
        "| `--early-stop` | Prevent overfitting | Always include |\n",
        "| `--eval-auto-carveout` | Auto validation split | Always include |"
      ],
      "metadata": {
        "id": "Eu252p5kGtgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import re\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Create unique model name\n",
        "model_name = f\"pubtabnet-table-qa-{timestamp}\"\n",
        "display_name = f\"pubtabnet-table-qa Fine-tune {timestamp}\"\n",
        "\n",
        "print(\"üöÄ Creating fine-tuning job...\")\n",
        "print(f\"üìã Dataset: {dataset_name}\")\n",
        "print(f\"üìã Output Model: {model_name}\")\n",
        "\n",
        "# Check if firectl exists and make it executable\n",
        "firectl_path = \"./firectl\"\n",
        "if os.path.exists(firectl_path):\n",
        "    # Make firectl executable\n",
        "    os.chmod(firectl_path, 0o755)\n",
        "    print(f\"‚úÖ Found firectl at {firectl_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå firectl not found at {firectl_path}\")\n",
        "    exit(1)\n",
        "\n",
        "# Build the fine-tuning command - FIXED: separate arguments properly\n",
        "cmd = [\n",
        "    firectl_path,\n",
        "    \"create\", \"supervised-fine-tuning-job\",\n",
        "    \"--base-model\", \"accounts/fireworks/models/qwen2p5-vl-32b-instruct\",\n",
        "    \"--dataset\", dataset_name,\n",
        "    \"--output-model\", model_name,\n",
        "    \"--display-name\", display_name,\n",
        "    \"--epochs\", \"3\",\n",
        "    \"--learning-rate\", \"0.0001\",\n",
        "    \"--turbo\",\n",
        "    \"--early-stop\",\n",
        "    \"--eval-auto-carveout\"\n",
        "]\n",
        "\n",
        "print(f\"üîß Running: {' '.join(cmd)}\")\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"‚úÖ Fine-tuning job created successfully!\")\n",
        "    print(result.stdout)\n",
        "\n",
        "    # Extract job ID from output\n",
        "    pattern = r\"Name: accounts/[^/]+/supervisedFineTuningJobs/([a-zA-Z0-9]+)\"\n",
        "\n",
        "    match = re.search(pattern, result.stdout)\n",
        "    if match:\n",
        "        job_id = match.group(1)\n",
        "        print(f\"üéØ Job ID: {job_id}\")\n",
        "        print(f\"üí° Save this: export JOB_ID='{job_id}'\")\n",
        "        print(f\"\\nüîç Monitor with: ./firectl get supervised-fine-tuning-job {job_id}\")\n",
        "    else:\n",
        "        print(\"üí° Job created but couldn't extract ID. Check the output above.\")\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"‚ùå Fine-tuning job creation failed: {e}\")\n",
        "    print(f\"Error output: {e.stderr}\")\n",
        "    if \"dataset\" in str(e.stderr).lower():\n",
        "        print(\"üí° Make sure your dataset was uploaded successfully first!\")\n",
        "    elif \"not found\" in str(e.stderr).lower():\n",
        "        print(\"üí° Check if the dataset name is correct\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå firectl binary not found or not executable.\")"
      ],
      "metadata": {
        "id": "AX2qUsTuGrrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Monitor Training Progress\n",
        "\n",
        "## üìã Section Overview\n",
        "- Check job status with CLI commands\n",
        "- Monitor training metrics\n",
        "- Know when training is complete\n",
        "\n",
        "## üìä Monitoring Commands\n",
        "\n",
        "Check your job status with these commands:\n",
        "\n",
        "```bash\n",
        "# List all jobs\n",
        "firectl list supervised-fine-tuning-jobs\n",
        "\n",
        "# Check specific job\n",
        "firectl get supervised-fine-tuning-job JOB_ID\n",
        "\n",
        "# Check your models (after completion)\n",
        "firectl list model\n",
        "```"
      ],
      "metadata": {
        "id": "wCAdBbIOHdtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "print(\"üìä Monitoring your fine-tuning job...\")\n",
        "print(f\"üéØ Job ID: {job_id}\")\n",
        "\n",
        "# Check if firectl exists and make it executable\n",
        "firectl_path = \"./firectl\"\n",
        "if os.path.exists(firectl_path):\n",
        "    # Make firectl executable\n",
        "    os.chmod(firectl_path, 0o755)\n",
        "    print(f\"‚úÖ Found firectl at {firectl_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå firectl not found at {firectl_path}\")\n",
        "    exit(1)\n",
        "\n",
        "try:\n",
        "    # FIXED: Separate arguments properly and use ./firectl\n",
        "    cmd = [firectl_path, \"-a\", \"pyroworks\", \"get\", \"supervised-fine-tuning-job\", job_id]\n",
        "    print(f\"üîß Running: {' '.join(cmd)}\")\n",
        "\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"‚úÖ Job details:\")\n",
        "    print(result.stdout)\n",
        "\n",
        "    # Check if job is completed\n",
        "    if \"JOB_STATE_COMPLETED\" in result.stdout:\n",
        "        print(\"üéâ Job completed! Ready for deployment.\")\n",
        "    elif \"JOB_STATE_RUNNING\" in result.stdout:\n",
        "        print(\"‚è≥ Job is still running...\")\n",
        "    elif \"JOB_STATE_VALIDATING\" in result.stdout:\n",
        "        print(\"üîç Job is validating...\")\n",
        "    elif \"JOB_STATE_QUEUED\" in result.stdout:\n",
        "        print(\"üìã Job is queued...\")\n",
        "    else:\n",
        "        print(\"üìä Check the status above for current state.\")\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"‚ùå Failed to check job {job_id}: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "    if \"not found\" in str(e.stderr).lower():\n",
        "        print(\"üí° Make sure the job ID is correct\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå firectl binary not found or not executable.\")\n",
        "\n",
        "# Optional: List all jobs to see what's available\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìã All your fine-tuning jobs:\")\n",
        "try:\n",
        "    cmd_list = [firectl_path, \"-a\", \"pyroworks\", \"list\", \"supervised-fine-tuning-jobs\"]\n",
        "    result_list = subprocess.run(cmd_list, capture_output=True, text=True, check=True)\n",
        "    print(result_list.stdout)\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to list jobs: {e}\")"
      ],
      "metadata": {
        "id": "T357uUgJHfCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Deploy Your Model\n",
        "\n",
        "Once training is **JOB_STATE_COMPLETED**, deploy your model:\n",
        "\n",
        "```bash\n",
        "firectl create deployment accounts/pyroworks/models/MODEL_NAME --enable-addons\n",
        "```\n"
      ],
      "metadata": {
        "id": "-qFXVZ26Htm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute model deployment\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "# Check if firectl exists and make it executable\n",
        "firectl_path = \"./firectl\"\n",
        "if os.path.exists(firectl_path):\n",
        "    # Make firectl executable\n",
        "    os.chmod(firectl_path, 0o755)\n",
        "    print(f\"‚úÖ Found firectl at {firectl_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå firectl not found at {firectl_path}\")\n",
        "    exit(1)\n",
        "\n",
        "# Build deployment command (using the model name from earlier)\n",
        "model_path = f\"accounts/pyroworks/models/{model_name}\"\n",
        "\n",
        "# FIXED: Separate arguments properly and use ./firectl\n",
        "cmd = [firectl_path, \"-a\", \"pyroworks\", \"create\", \"deployment\", model_path, \"--enable-addons\"]\n",
        "\n",
        "print(f\"üîß Running: {' '.join(cmd)}\")\n",
        "print(\"‚è≥ Note: This will only work if your fine-tuning job has COMPLETED\")\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"‚úÖ Model deployment successful!\")\n",
        "    print(result.stdout)\n",
        "\n",
        "    # Extract deployment ID\n",
        "    pattern = r\"Name: accounts/[^/]+/deployments/([a-zA-Z0-9]+)\"\n",
        "    match = re.search(pattern, result.stdout)\n",
        "    if match:\n",
        "        deployment_id = match.group(1)\n",
        "        print(f\"üéØ Deployment ID: {deployment_id}\")\n",
        "        print(f\"üí° Save this: export DEPLOYMENT_ID='{deployment_id}'\")\n",
        "        print(f\"\\nüåê Your model is now available for API calls!\")\n",
        "    else:\n",
        "        print(\"üí° Deployment created but couldn't extract ID. Check the output above.\")\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"‚ùå Deployment failed: {e}\")\n",
        "    print(f\"Error output: {e.stderr}\")\n",
        "    if \"not found\" in str(e.stderr):\n",
        "        print(\"üí° Make sure your fine-tuning job completed successfully first!\")\n",
        "        print(\"üí° Check job status with: ./firectl list supervised-fine-tuning-jobs\")\n",
        "    elif \"model\" in str(e.stderr).lower():\n",
        "        print(\"üí° Make sure the model name is correct\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå firectl binary not found or not executable.\")\n",
        "\n",
        "# Optional: List all your models to verify the fine-tuned model exists\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìã Your available models:\")\n",
        "try:\n",
        "    cmd_list = [firectl_path, \"list\", \"models\"]\n",
        "    result_list = subprocess.run(cmd_list, capture_output=True, text=True, check=True)\n",
        "    print(result_list.stdout)\n",
        "\n",
        "    # Check if our model is in the list\n",
        "    if model_name in result_list.stdout:\n",
        "        print(f\"‚úÖ Found your fine-tuned model: {model_name}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  Your model '{model_name}' not found in the list above.\")\n",
        "        print(\"üí° Make sure your fine-tuning job completed successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to list models: {e}\")"
      ],
      "metadata": {
        "id": "wO9Qrc1wHu1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! firectl get deployment {deployment_id}"
      ],
      "metadata": {
        "id": "yIyErMMZLbkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Test Your Model\n",
        "\n",
        "## üß™ Query with curl\n",
        "\n",
        "Test your deployed model from the command line:\n",
        "\n",
        "```bash\n",
        "curl --request POST \\\n",
        "  --url https://api.fireworks.ai/inference/v1/chat/completions \\\n",
        "  -H 'Accept: application/json' \\\n",
        "  -H 'Content-Type: application/json' \\\n",
        "  -H 'Authorization: Bearer $FIREWORKS_API_KEY' \\\n",
        "  --data '{\n",
        "    \"model\": \"accounts/pyroworks/deployedModels/pubtabnet-table-qa-20250804-032004-tv6p517x\",\n",
        "    \"max_tokens\": 4000,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 40,\n",
        "    \"presence_penalty\": 0,\n",
        "    \"frequency_penalty\": 0,\n",
        "    \"temperature\": 0.6,\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"Can you describe this image?\"\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://images.unsplash.com/photo-1582538885592-e70a5d7ab3d3?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1770&q=80\"\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "  }'\n",
        "```\n"
      ],
      "metadata": {
        "id": "ZXEAjssKNwFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your fine-tuned VLM model on test dataset\n",
        "import requests\n",
        "import os\n",
        "import random\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "print(\"üß™ Testing your fine-tuned VLM model on test dataset...\")\n",
        "\n",
        "# Get first 5 test examples\n",
        "test_examples = ds_test.select(range(5))\n",
        "print(f\"Selected {len(test_examples)} test examples\")\n",
        "\n",
        "# Convert test images to base64\n",
        "def pil_to_base64(pil_image):\n",
        "    \"\"\"Convert PIL Image to base64 string\"\"\"\n",
        "    buffered = BytesIO()\n",
        "    pil_image.save(buffered, format=\"PNG\")\n",
        "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "    return f\"data:image/png;base64,{img_str}\"\n",
        "\n",
        "def display_image_from_base64(base64_string, title=\"Image\"):\n",
        "    \"\"\"Display image from base64 string\"\"\"\n",
        "    try:\n",
        "        # Extract and decode the base64 image\n",
        "        if ',' in base64_string:\n",
        "            image_data = base64_string.split(',')[1]\n",
        "        else:\n",
        "            image_data = base64_string\n",
        "\n",
        "        # Decode base64 to image\n",
        "        image_bytes = base64.b64decode(image_data)\n",
        "        image = Image.open(BytesIO(image_bytes))\n",
        "\n",
        "        # Display using matplotlib\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.title(title, fontsize=12, pad=15)\n",
        "        plt.show()\n",
        "\n",
        "        return image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error displaying image: {e}\")\n",
        "        return None\n",
        "\n",
        "# Convert test images\n",
        "test_base64_data = []\n",
        "for i in range(5):\n",
        "    example = test_examples[i]\n",
        "    base64_image = pil_to_base64(example['image'])\n",
        "    test_base64_data.append({\n",
        "        'image_base64': base64_image,\n",
        "        'imgid': example['imgid'],\n",
        "        'html_table': example['html_table'],\n",
        "        'original_image': example['image']  # Keep original PIL image for easier display\n",
        "    })\n",
        "\n",
        "# Question templates\n",
        "question_templates = [\n",
        "    \"What information is shown in this table?\",\n",
        "    \"Describe the content and structure of this table.\",\n",
        "    \"What data does this table contain?\",\n",
        "    \"Can you analyze this table and tell me what it shows?\",\n",
        "    \"What are the main elements of this table?\",\n",
        "    \"Summarize the information presented in this table.\",\n",
        "    \"What can you tell me about the data in this table?\",\n",
        "    \"Describe what this table is displaying.\",\n",
        "]\n",
        "\n",
        "# Model configuration - UPDATE THESE VALUES\n",
        "model_name = \"pubtabnet-table-qa-20250804-032004-tv6p517x\"  # Replace with your actual model name\n",
        "model_id = f\"accounts/pyroworks/deployedModels/{model_name}\"\n",
        "url = \"https://api.fireworks.ai/inference/v1/chat/completions\"\n",
        "\n",
        "# Get API key from environment\n",
        "api_key = os.environ.get('FIREWORKS_API_KEY')\n",
        "if not api_key:\n",
        "    print(\"‚ùå FIREWORKS_API_KEY not found in environment variables\")\n",
        "    print(\"Please set it using: os.environ['FIREWORKS_API_KEY'] = 'your_key'\")\n",
        "else:\n",
        "    print(\"‚úÖ API key found\")\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "print(f\"üéØ Testing model: {model_id}\")\n",
        "print(\"‚è≥ Note: Model must be deployed first!\")\n",
        "\n",
        "# Test each image\n",
        "results = []\n",
        "\n",
        "for i, test_data in enumerate(test_base64_data):\n",
        "    # Pick a random question for this image\n",
        "    question = random.choice(question_templates)\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*80)\n",
        "    print(f\"üìã Test {i+1}: Image ID {test_data['imgid']}\")\n",
        "    print(f\"‚ùì Question: {question}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Display the image\n",
        "    print(f\"\\nüñºÔ∏è Displaying test image:\")\n",
        "    display_image_from_base64(\n",
        "        test_data['image_base64'],\n",
        "        title=f\"Test {i+1}: {test_data['imgid']} - {question[:50]}...\"\n",
        "    )\n",
        "\n",
        "    data = {\n",
        "        \"model\": model_id,\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful assistant that can analyze tables and documents to answer questions about their content. Focus on understanding what information is presented and be ready to answer specific questions about the data.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": test_data['image_base64']\n",
        "                        }\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": question\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"temperature\": 0.1,\n",
        "        \"max_tokens\": 500\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        print(\"üîÑ Sending request to model...\")\n",
        "        response = requests.post(url, headers=headers, json=data)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        result = response.json()\n",
        "        model_response = result['choices'][0]['message']['content'].strip()\n",
        "\n",
        "        print(f\"\\nü§ñ Model Response:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(model_response)\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Store result for comparison\n",
        "        results.append({\n",
        "            'image_id': test_data['imgid'],\n",
        "            'question': question,\n",
        "            'model_response': model_response,\n",
        "            'ground_truth_html': test_data['html_table'],\n",
        "            'image': test_data['original_image']\n",
        "        })\n",
        "\n",
        "        print(f\"‚úÖ Test {i+1} completed successfully!\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå Request failed: {e}\")\n",
        "        if hasattr(e, 'response') and e.response is not None:\n",
        "            print(f\"Response: {e.response.text}\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(f\"‚úÖ Testing complete! Processed {len(results)} examples\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "IGhAM0HdOfhY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}