{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iansawicki/fireworks/blob/main/notebooks/Supervised_Fine_Tuning_Text2SQL_on_Fireworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782827ef",
      "metadata": {
        "id": "782827ef"
      },
      "source": [
        "# Supervised Fine-Tuning Text2SQL on Fireworks\n",
        "\n",
        "This notebook demonstrates the **Fireworks CLI commands** for fine-tuning with minimal Python wrapper code.\n",
        "\n",
        "## 📋 Table of Contents\n",
        "\n",
        "| Section | Description | Key CLI Commands |\n",
        "|---------|-------------|------------------|\n",
        "| **0. Setup** | Install dependencies and environment | - |\n",
        "| **1. Authentication** | Setup CLI and verify credentials | `firectl signin`, `firectl whoami` |\n",
        "| **2. Dataset Preparation** | Load and convert Spider dataset | - |\n",
        "| **3. Dataset Upload** | Upload to Fireworks (Local + GCS) | `firectl create dataset` |\n",
        "| **4. Fine-tuning** | Create and monitor training job | `firectl create supervised-fine-tuning-job` |\n",
        "| **5. Deployment** | Deploy trained model | `firectl create deployment` & `firectl load-lora` |\n",
        "| **6. Testing** | Query your deployed model | `curl` + Python requests |\n",
        "| **7. Duck DB Demo** | Query your deployed model | Python requests + LM Created Queries|\n",
        "\n",
        "## 🎯 What You'll Learn\n",
        "\n",
        "- **CLI Commands**: The exact `firectl` commands to run\n",
        "- **End-to-End Workflow**: From dataset to deployed model  \n",
        "- **Two Approaches**: Local files vs. Google Cloud Storage\n",
        "- **Best Practices**: Dataset formats, fine-tuning parameters, testing\n",
        "\n",
        "## 📋 Prerequisites\n",
        "\n",
        "1. **Fireworks AI Account**: Sign up at [fireworks.ai](https://fireworks.ai)\n",
        "2. **Fireworks CLI (mac)**: `brew tap fw-ai/firectl && brew install firectl`\n",
        "3. **API Key**: `export FIREWORKS_API_KEY='your-key'`\n",
        "4. **Optional**: HuggingFace token for private datasets\n",
        "\n",
        "## 🚀 Quick Start\n",
        "\n",
        "If you just want the commands, here's the complete workflow:\n",
        "\n",
        "```bash\n",
        "# 1. Setup\n",
        "export FIREWORKS_API_KEY='your-key'\n",
        "firectl signin\n",
        "\n",
        "# 2. Upload dataset (choose one)\n",
        "firectl create dataset my-dataset ./data.jsonl                    # Local file\n",
        "firectl create dataset my-dataset --external-url gs://bucket/data.jsonl  # GCS\n",
        "\n",
        "# 3. Start fine-tuning\n",
        "firectl create supervised-fine-tuning-job \\\n",
        "  --dataset my-dataset --output-model my-model \\\n",
        "  --base-model accounts/fireworks/models/qwen2p5-coder-32b-instruct \\\n",
        "  --epochs 3 --turbo --early-stop --eval-auto-carveout\n",
        "\n",
        "# 4. Monitor and deploy\n",
        "firectl get supervised-fine-tuning-job JOB_ID\n",
        "firectl create deployment accounts/ACCOUNT/models/my-model --enable-addons\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bbf2630",
      "metadata": {
        "id": "2bbf2630"
      },
      "source": [
        "# 1. Authentication & Environment Setup\n",
        "\n",
        "## 📋 Section Overview\n",
        "- Install Fireworks CLI\n",
        "- Set API key and authenticate\n",
        "- Verify setup with Python\n",
        "- Optional: Setup HuggingFace access\n",
        "\n",
        "## 🔧 Required CLI Commands\n",
        "\n",
        "Run these commands in your terminal **before** running this notebook:\n",
        "\n",
        "```bash\n",
        "# 1. Install Fireworks CLI (on mac)\n",
        "brew tap fw-ai/firectl && brew install firectl\n",
        "\n",
        "# Or Linux (If you're using Collab, do this in the terminal.)\n",
        "wget -O firectl.gz https://storage.googleapis.com/fireworks-public/firectl/stable/linux-amd64.gz\n",
        "gunzip firectl.gz\n",
        "sudo install -o root -g root -m 0755 firectl /usr/local/bin/firectl\n",
        "\n",
        "# 2. Sign into Fireworks\n",
        "firectl signin\n",
        "\n",
        "# 3. Verify authentication\n",
        "firectl whoami\n",
        "\n",
        "# 4. Set your HF API key\n",
        "export HUGGINGFACE_HUB_TOKEN='<your-hf-token-here>\n",
        "\n",
        "# 5. Set your API key\n",
        "export FIREWORKS_API_KEY='<your-api-key-here>'\n",
        "```\n",
        "\n",
        "**Important**: The Python code below will check if these steps were completed successfully."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "datasets>=2.14.0,<2.16.0\n",
        "huggingface-hub>=0.17.0,<0.20.0\n",
        "requests==2.32.3\n",
        "pandas==2.2.2\n",
        "pyarrow>=14.0.0,<16.0.0\n",
        "fsspec>=2023.1.0,<2024.0.0"
      ],
      "metadata": {
        "id": "NOTPGcmFyQ_H"
      },
      "id": "NOTPGcmFyQ_H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install notebook dependencies\n",
        "!pip cache purge\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "ZQzHVmphyXf0"
      },
      "id": "ZQzHVmphyXf0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2F7MzJPlXZlY",
      "metadata": {
        "id": "2F7MzJPlXZlY"
      },
      "outputs": [],
      "source": [
        "# Install Fireworks CLI (on linux)\n",
        "! wget -O firectl.gz https://storage.googleapis.com/fireworks-public/firectl/stable/linux-amd64.gz\n",
        "! gunzip firectl.gz\n",
        "! sudo install -o root -g root -m 0755 firectl /usr/local/bin/firectl\n",
        "\n",
        "# Sign into fireworks firectl CLI\n",
        "! firectl signin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, sys, os\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# Use getpass to get the API keys securely\n",
        "FIREWORKS_API_KEY = getpass.getpass('Enter your Fireworks API Key: ')\n",
        "HUGGINGFACE_HUB_TOKEN = getpass.getpass('Enter your HuggingFace Hub Token (optional): ')\n",
        "\n",
        "# Set the environment variables\n",
        "os.environ[\"FIREWORKS_API_KEY\"] = FIREWORKS_API_KEY\n",
        "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = HUGGINGFACE_HUB_TOKEN\n",
        "\n",
        "print(\"API keys set securely.\")"
      ],
      "metadata": {
        "id": "SXSBpEeaW6tn"
      },
      "id": "SXSBpEeaW6tn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e6bc3b",
      "metadata": {
        "id": "38e6bc3b"
      },
      "outputs": [],
      "source": [
        "# Setup HuggingFace Authentication (Optional)\n",
        "\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "\n",
        "print(\"🤗 Setting up HuggingFace authentication...\")\n",
        "\n",
        "hf_token = HUGGINGFACE_HUB_TOKEN\n",
        "if hf_token:\n",
        "    login(token=hf_token)\n",
        "    print(\"✅ Logged into HuggingFace!\")\n",
        "else:\n",
        "    print(\"⚠️  No HUGGINGFACE_HUB_TOKEN found (this is optional for public datasets)\")\n",
        "    print(\"💡 For private datasets, get a token from: https://huggingface.co/settings/tokens\")\n",
        "    print(\"💡 Then set: export HUGGINGFACE_HUB_TOKEN='your_token_here'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93aafc7",
      "metadata": {
        "id": "b93aafc7"
      },
      "source": [
        "## ✅ Verify Setup\n",
        "\n",
        "This Python code checks if the CLI commands above were successful:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d26a512",
      "metadata": {
        "id": "0d26a512"
      },
      "outputs": [],
      "source": [
        "# Check Prerequisites\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "print(\"🔧 Checking Prerequisites...\")\n",
        "\n",
        "# Check API key\n",
        "api_key = FIREWORKS_API_KEY\n",
        "if api_key:\n",
        "    print(f\"✅ API Key found: {api_key[:10]}...\")\n",
        "else:\n",
        "    print(\"❌ No FIREWORKS_API_KEY found\")\n",
        "    print(\"💡 Set it with: export FIREWORKS_API_KEY='your-key'\")\n",
        "\n",
        "# Check firectl\n",
        "try:\n",
        "    result = subprocess.run([\"firectl\", \"version\"], capture_output=True, text=True)\n",
        "    if result.returncode == 0:\n",
        "        print(f\"✅ firectl installed: {result.stdout.strip()}\")\n",
        "    else:\n",
        "        print(\"❌ firectl not working\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ firectl not found\")\n",
        "    print(\"💡 Install with: brew tap fw-ai/firectl && brew install firectl\")\n",
        "\n",
        "# Check if signed in\n",
        "try:\n",
        "    result = subprocess.run([\"firectl\", \"whoami\"], capture_output=True, text=True)\n",
        "    if result.returncode == 0:\n",
        "        print(\"✅ Signed into Fireworks CLI\")\n",
        "        print(result.stdout.strip())\n",
        "    else:\n",
        "        print(\"⚠️  Not signed into Fireworks CLI\")\n",
        "        print(\"💡 Sign in with: firectl signin\")\n",
        "except:\n",
        "    print(\"⚠️  Could not check Fireworks CLI status\")\n",
        "\n",
        "print(\"🚀 Prerequisites check complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82f31b0e",
      "metadata": {
        "id": "82f31b0e"
      },
      "source": [
        "# 2. Dataset Preparation\n",
        "\n",
        "## 📋 Section Overview\n",
        "- Load Spider Text2SQL dataset from HuggingFace\n",
        "- Convert to Chat Completions format (required by Fireworks)\n",
        "- Save as JSONL files for upload\n",
        "- Alternative: Use GCS datasets directly\n",
        "\n",
        "## 💡 GCS Alternative\n",
        "\n",
        "If your data is already in Google Cloud Storage, you can skip data preparation and use:\n",
        "\n",
        "```bash\n",
        "# Upload dataset directly from GCS (no local file needed)\n",
        "firectl create dataset my-dataset-name \\\n",
        "  --external-url gs://your-bucket/path/to/dataset.jsonl\n",
        "```\n",
        "\n",
        "For this example, we'll prepare data locally to show the complete workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08918907",
      "metadata": {
        "id": "08918907"
      },
      "outputs": [],
      "source": [
        "# Optional: Setup GCS Bucket Access (Skip if using local files only)\n",
        "print(\"🔐 Setting up GCS bucket access for Fireworks...\")\n",
        "print(\"💡 This is only needed if you want to use the GCS upload method\")\n",
        "\n",
        "# For GCS datasets, Fireworks needs access to your bucket\n",
        "# The commands below grant the necessary permissions\n",
        "print(\"\"\"\n",
        "📋 To setup GCS access, run these gcloud commands:\n",
        "\n",
        "# Grant access to Fireworks service accounts\n",
        "gcloud storage buckets add-iam-policy-binding gs://your-bucket \\\\\n",
        "  --member=serviceAccount:fireworks-control-plane@<your-project-here>.iam.gserviceaccount.com \\\\\n",
        "  --role=roles/storage.objectViewer\n",
        "\n",
        "gcloud storage buckets add-iam-policy-binding gs://your-bucket \\\\\n",
        "  --member=serviceAccount:inference@your-project-here>.iam.gserviceaccount.com \\\\\n",
        "  --role=roles/storage.objectViewer\n",
        "\n",
        "📚 More info: https://docs.fireworks.ai/fine-tuning/fine-tuning-external-dataset\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab67e847",
      "metadata": {
        "id": "ab67e847"
      },
      "source": [
        "## 📊 Load Spider Dataset\n",
        "\n",
        "We'll use the Spider Text2SQL dataset: [xlangai/spider](https://huggingface.co/datasets/xlangai/spider).\n",
        "\n",
        "This is a widely-used benchmark with 7,000 training examples for text-to-SQL generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8684735c",
      "metadata": {
        "id": "8684735c"
      },
      "outputs": [],
      "source": [
        "# Load Spider Text2SQL dataset from HuggingFace\n",
        "\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(\"📊 Loading Spider dataset...\")\n",
        "\n",
        "dataset = load_dataset(\"spider\", cache_dir=\"/tmp/hf_cache\")\n",
        "\n",
        "df = pd.DataFrame(dataset[\"train\"])\n",
        "\n",
        "print(f\"✅ Dataset loaded: {len(df):,} examples\")\n",
        "print(f\"📊 Columns: {list(df.columns)}\")\n",
        "\n",
        "# Show sample data\n",
        "print(\"\\n📋 Sample text-to-SQL examples:\")\n",
        "sample_data = df[['question', 'query']].head(3)\n",
        "for idx, row in sample_data.iterrows():\n",
        "    print(f\"\\n{idx + 1}. Question: {row['question']}\")\n",
        "    print(f\"   SQL: {row['query']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9cbcd17",
      "metadata": {
        "id": "a9cbcd17"
      },
      "source": [
        "# 3. Dataset Upload to Fireworks\n",
        "\n",
        "## 📋 Section Overview\n",
        "- Convert data to Chat Completions format (required by Fireworks)\n",
        "- Create JSONL files for upload\n",
        "- Upload using `firectl create dataset` command\n",
        "- Show both local file and GCS upload methods\n",
        "\n",
        "## 🔄 Convert to Chat Completions Format\n",
        "\n",
        "Fireworks requires data in Chat Completions format with `system`, `user`, and `assistant` messages."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05206f7f",
      "metadata": {
        "id": "05206f7f"
      },
      "source": [
        "Each training example needs three parts:\n",
        "- **System**: Instructions for the model\n",
        "- **User**: The natural language question  \n",
        "- **Assistant**: The expected SQL query response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f137fec",
      "metadata": {
        "id": "2f137fec"
      },
      "outputs": [],
      "source": [
        "# Create example in Chat Completions format\n",
        "import json\n",
        "\n",
        "# System prompt for Text2SQL fine-tuning\n",
        "SYSTEM_PROMPT = \"\"\"You are a SQL query generator. Your task is to convert natural language questions into valid SQL queries.\n",
        "\n",
        "Rules:\n",
        "- Return ONLY the SQL query\n",
        "- No explanations or comments\n",
        "- No markdown code blocks or formatting\n",
        "- No references to examples, repositories, or documentation\n",
        "- No prefacing text like \"Here's the query:\" or \"The SQL is:\"\n",
        "\n",
        "Just return the raw SQL query.\"\"\"\n",
        "\n",
        "# Example format\n",
        "example = {\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": df.iloc[0][\"question\"]},\n",
        "        {\"role\": \"assistant\", \"content\": df.iloc[0][\"query\"]}\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"📋 Chat Completions format example:\")\n",
        "print(json.dumps(example, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec3ac815",
      "metadata": {
        "id": "ec3ac815"
      },
      "source": [
        "## 💾 Create JSONL Files\n",
        "\n",
        "For this demo, we'll use 1,000 examples for faster training. You can use the full 7,000 examples for better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce35c8c4",
      "metadata": {
        "id": "ce35c8c4"
      },
      "outputs": [],
      "source": [
        "# Convert dataset to JSONL format\n",
        "from datetime import datetime\n",
        "import random\n",
        "\n",
        "# Create sampled dataset for faster training\n",
        "sampled_df = df.sample(n=1000, random_state=42)\n",
        "\n",
        "def df_to_jsonl(df, output_file):\n",
        "    \"\"\"Convert DataFrame to JSONL with Chat Completions format\"\"\"\n",
        "    with open(output_file, 'w') as f:\n",
        "        for _, row in df.iterrows():\n",
        "            chat_record = {\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                    {\"role\": \"user\", \"content\": row[\"question\"]},\n",
        "                    {\"role\": \"assistant\", \"content\": row[\"query\"]}\n",
        "                ]\n",
        "            }\n",
        "            f.write(json.dumps(chat_record) + '\\n')\n",
        "    print(f\"✅ Saved {len(df)} examples to {output_file}\")\n",
        "\n",
        "# Create files with timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "full_file = f\"spider_full_{timestamp}.jsonl\"\n",
        "sample_file = f\"spider_1k_{timestamp}.jsonl\"\n",
        "\n",
        "# Save both datasets\n",
        "df_to_jsonl(sampled_df, sample_file)\n",
        "df_to_jsonl(df, full_file)\n",
        "\n",
        "print(f\"\\n📄 Files created:\")\n",
        "print(f\"   📋 Sample dataset: {sample_file}\")\n",
        "print(f\"   📋 Full dataset: {full_file}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ef1cab0",
      "metadata": {
        "id": "6ef1cab0"
      },
      "source": [
        "## 📤 Upload Dataset - Local File Method\n",
        "\n",
        "Upload your JSONL file to Fireworks:\n",
        "\n",
        "```bash\n",
        "firectl create dataset DATASET_NAME ./your-file.jsonl\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f16e3e1d",
      "metadata": {
        "id": "f16e3e1d"
      },
      "outputs": [],
      "source": [
        "# Execute the dataset upload command\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Create unique dataset name\n",
        "dataset_name = f\"spider-text2sql-full-{timestamp}\"\n",
        "\n",
        "print(f\"📤 Uploading dataset: {dataset_name}\")\n",
        "print(f\"📄 File: {full_file}\")\n",
        "\n",
        "# Build and run the command\n",
        "cmd = [\"firectl\",  \"create\", \"dataset\", dataset_name, sample_file]\n",
        "print(f\"🔧 Running: {' '.join(cmd)}\")\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Dataset upload successful!\")\n",
        "    print(result.stdout)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ Upload failed: {e}\")\n",
        "    print(f\"Error output: {e.stderr}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ firectl not found. Make sure it's installed and in your PATH.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VwPbRiVIZHqI",
      "metadata": {
        "id": "VwPbRiVIZHqI"
      },
      "outputs": [],
      "source": [
        "! firectl get dataset {dataset_name}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81182d82",
      "metadata": {
        "id": "81182d82"
      },
      "source": [
        "## 🌐 Alternative: Upload from GCS\n",
        "\n",
        "If your data is already in Google Cloud Storage:\n",
        "\n",
        "```bash\n",
        "firectl create dataset DATASET_NAME --external-url gs://your-bucket/path/to/dataset.jsonl\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01da4278",
      "metadata": {
        "id": "01da4278"
      },
      "outputs": [],
      "source": [
        "# The same transformed Text2Sql dataset \"spider\" is available in this public GCS bucket as well\n",
        "\n",
        "! curl -s https://storage.googleapis.com/fireworks-demos/sft_sample_data/spider_original_full_7k.jsonl | head -c 200\n",
        "\n",
        "dataset_name_gcs = dataset_name + \"-gcs\"\n",
        "! firectl create dataset {dataset_name_gcs} --external-url gs://fireworks-demos/sft_sample_data/spider_original_full_7k.jsonl\n",
        "print(\"Uploading dataset to Fireworks from a GCS Bucket: \", dataset_name_gcs)\n",
        "\n",
        "# Check dataset exists\n",
        "! firectl get dataset {dataset_name_gcs}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a0bbad3",
      "metadata": {
        "id": "3a0bbad3"
      },
      "source": [
        "# 4. Create Fine-tuning Job\n",
        "\n",
        "## 📋 Section Overview  \n",
        "- Create fine-tuning job with `firectl create supervised-fine-tuning-job`\n",
        "- Monitor training progress\n",
        "- Best practices for parameters\n",
        "\n",
        "## 🚀 Start Fine-tuning\n",
        "\n",
        "Here's the key CLI command to start training:\n",
        "\n",
        "```bash\n",
        "firectlcreate supervised-fine-tuning-job \\\n",
        "  --base-model accounts/fireworks/models/qwen2p5-coder-32b-instruct \\\n",
        "  --dataset DATASET_NAME \\\n",
        "  --output-model MODEL_NAME \\\n",
        "  --display-name \"Text2SQL Fine-tune\" \\\n",
        "  --epochs 3 \\\n",
        "  --learning-rate 0.0001 \\\n",
        "  --turbo \\\n",
        "  --early-stop \\\n",
        "  --eval-auto-carveout\n",
        "```\n",
        "\n",
        "## 📊 Parameter Guide\n",
        "\n",
        "| Parameter | Description | Recommended Value |\n",
        "|-----------|-------------|-------------------|\n",
        "| `--base-model` | Base model to fine-tune | `qwen2p5-coder-32b-instruct` |\n",
        "| `--dataset` | Your uploaded dataset ID | From step 3 |\n",
        "| `--output-model` | Name for your fine-tuned model | `my-text2sql-model` |\n",
        "| `--epochs` | Training iterations | `3` (start small) |\n",
        "| `--learning-rate` | Learning rate | `0.0001` |\n",
        "| `--turbo` | Faster training | Always include |\n",
        "| `--early-stop` | Prevent overfitting | Always include |\n",
        "| `--eval-auto-carveout` | Auto validation split | Always include |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066bfa49",
      "metadata": {
        "id": "066bfa49"
      },
      "outputs": [],
      "source": [
        "# Execute fine-tuning job creation\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "# Create unique model name\n",
        "model_name = f\"spider-sql-{timestamp}\"\n",
        "display_name = f\"Text2SQL Fine-tune {timestamp}\"\n",
        "\n",
        "print(\"🚀 Creating fine-tuning job...\")\n",
        "print(f\"📋 Dataset: {dataset_name}\")\n",
        "print(f\"📋 Output Model: {model_name}\")\n",
        "\n",
        "# Build the fine-tuning command\n",
        "cmd = [\n",
        "    \"firectl\",\n",
        "    \"create\", \"supervised-fine-tuning-job\",\n",
        "    \"--base-model\", \"accounts/fireworks/models/qwen2p5-coder-32b-instruct\",\n",
        "    \"--dataset\", dataset_name,\n",
        "    \"--output-model\", model_name,\n",
        "    \"--display-name\", display_name,\n",
        "    \"--epochs\", \"3\",\n",
        "    \"--learning-rate\", \"0.0001\",\n",
        "    \"--turbo\",\n",
        "    \"--early-stop\",\n",
        "    \"--eval-auto-carveout\"\n",
        "]\n",
        "\n",
        "print(f\"🔧 Running: {' '.join(cmd)}\")\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Fine-tuning job created successfully!\")\n",
        "    print(result.stdout)\n",
        "\n",
        "    # Extract job ID from output\n",
        "    pattern = r\"Name: accounts/[^/]+/supervisedFineTuningJobs/([a-zA-Z0-9]+)\"\n",
        "\n",
        "    match = re.search(pattern, result.stdout)\n",
        "    if match:\n",
        "        job_id = match.group(1)\n",
        "        print(f\"🎯 Job ID: {job_id}\")\n",
        "        print(f\"💡 Save this: export JOB_ID='{job_id}'\")\n",
        "        print(f\"\\n🔍 Monitor with: firectl get supervised-fine-tuning-job {job_id}\")\n",
        "    else:\n",
        "        print(\"💡 Job created but couldn't extract ID. Check the output above.\")\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ Fine-tuning job creation failed: {e}\")\n",
        "    print(f\"Error output: {e.stderr}\")\n",
        "    if \"dataset\" in str(e.stderr).lower():\n",
        "        print(\"💡 Make sure your dataset was uploaded successfully first!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ firectl not found. Make sure it's installed and in your PATH.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39a3b99a",
      "metadata": {
        "id": "39a3b99a"
      },
      "source": [
        "# 5. Monitor Training Progress\n",
        "\n",
        "## 📋 Section Overview\n",
        "- Check job status with CLI commands\n",
        "- Monitor training metrics\n",
        "- Know when training is complete\n",
        "\n",
        "## 📊 Monitoring Commands\n",
        "\n",
        "Check your job status with these commands:\n",
        "\n",
        "```bash\n",
        "# List all jobs\n",
        "firectl list supervised-fine-tuning-jobs\n",
        "\n",
        "# Check specific job\n",
        "firectl get supervised-fine-tuning-job JOB_ID\n",
        "\n",
        "# Check your models (after completion)\n",
        "firectl list model\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f31a71",
      "metadata": {
        "id": "e2f31a71"
      },
      "outputs": [],
      "source": [
        "# Execute monitoring commands\n",
        "import subprocess\n",
        "\n",
        "print(\"📊 Monitoring your fine-tuning job...\")\n",
        "\n",
        "try:\n",
        "    cmd = [\"firectl\", \"get\", \"supervised-fine-tuning-job\", job_id]\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Job details:\")\n",
        "    print(result.stdout)\n",
        "\n",
        "    # Check if job is completed\n",
        "    if \"JOB_STATE_COMPLETED\" in result.stdout:\n",
        "        print(\"🎉 Job completed! Ready for deployment.\")\n",
        "    elif \"JOB_STATE_RUNNING\" in result.stdout:\n",
        "        print(\"⏳ Job is still running...\")\n",
        "    elif \"JOB_STATE_VALIDATING\" in result.stdout:\n",
        "        print(\"🔍 Job is validating...\")\n",
        "    elif \"JOB_STATE_QUEUED\" in result.stdout:\n",
        "        print(\"📋 Job is queued...\")\n",
        "    else:\n",
        "        print(\"📊 Check the status above for current state.\")\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ Failed to check job {job_id}: {e}\")\n",
        "    print(f\"Error: {e.stderr}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ firectl not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42b24aa4",
      "metadata": {
        "id": "42b24aa4"
      },
      "source": [
        "## 🚀 Deploy Your Model\n",
        "\n",
        "Once training is **JOB_STATE_COMPLETED**, deploy your model:\n",
        "\n",
        "```bash\n",
        "firectl create deployment accounts/pyroworks/models/MODEL_NAME --enable-addons\n",
        "```\n",
        "\n",
        "This automatically merges the LoRA weights into the base model you trained on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2fcb7e7",
      "metadata": {
        "id": "c2fcb7e7"
      },
      "outputs": [],
      "source": [
        "# Execute model deployment\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "print(\"🚀 Deploying your fine-tuned model...\")\n",
        "\n",
        "# Build deployment command (using the model name from earlier)\n",
        "model_path = f\"accounts/pyroworks/models/{model_name}\"\n",
        "# Manually set your model path - demo purposes\n",
        "model_path = \"accounts/pyroworks/models/spider-sql-finetuned\" # accounts/fireworks/models/qwen2p5-coder-7b\n",
        "\n",
        "cmd = [\"firectl\",  \"create\", \"deployment\", model_path, \"--enable-addons\"]\n",
        "\n",
        "print(f\"🔧 Running: {' '.join(cmd)}\")\n",
        "print(\"⏳ Note: This will only work if your fine-tuning job has COMPLETED\")\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "    print(\"✅ Model deployment successful!\")\n",
        "    print(result.stdout)\n",
        "\n",
        "    # Extract deployment ID\n",
        "    pattern = r\"Name: accounts/[^/]+/deployments/([a-zA-Z0-9]+)\"\n",
        "    match = re.search(pattern, result.stdout)\n",
        "    if match:\n",
        "        deployment_id = match.group(1)\n",
        "        print(f\"🎯 Deployment ID: {deployment_id}\")\n",
        "        print(f\"💡 Save this: export DEPLOYMENT_ID='{deployment_id}'\")\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ Deployment failed: {e}\")\n",
        "    print(f\"Error output: {e.stderr}\")\n",
        "    if \"not found\" in str(e.stderr):\n",
        "        print(\"💡 Make sure your fine-tuning job completed successfully first!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ firectl not found. Make sure it's installed and in your PATH.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39fa10ae",
      "metadata": {
        "id": "39fa10ae"
      },
      "outputs": [],
      "source": [
        "! firectl get deployment {deployment_id}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use load LoRA instead for hosting multiple loras on the same endpoint\n",
        "* https://fireworks.ai/docs/fine-tuning/multi-lora\n",
        "\n",
        "Create a new base model deployment\n",
        "```bash\n",
        "firectl create deployement accounts/fireworks/models/qwen2p5-coder-7b-instruct\n",
        "```\n",
        "\n",
        "Load LoRA into the base deployment\n",
        "```bash\n",
        "firectl load-lora {model_path} --deployment=\"<deployment-id>\"\n",
        "```\n",
        "\n",
        "Load another LoRA into the base deployment\n",
        "```\n",
        "firectl load-lora {model_path_path_2} --deployment=\"<deployment-id>\"\n",
        "```"
      ],
      "metadata": {
        "id": "5z7-VEYXDLjw"
      },
      "id": "5z7-VEYXDLjw"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NU_EQMktZE8P"
      },
      "id": "NU_EQMktZE8P"
    },
    {
      "cell_type": "markdown",
      "id": "f8b44041",
      "metadata": {
        "id": "f8b44041"
      },
      "source": [
        "# 7. Test Your Model\n",
        "\n",
        "## 🧪 Query with curl\n",
        "\n",
        "Test your deployed model from the command line:\n",
        "\n",
        "```bash\n",
        "curl -X POST https://api.fireworks.ai/inference/v1/chat/completions \\\n",
        "  -H \"Authorization: Bearer $FIREWORKS_API_KEY\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\n",
        "    \"model\": \"accounts/pyroworks/models/spider-sql-sft20250722-115217,\n",
        "    \"messages\": [\n",
        "      {\"role\": \"system\", \"content\": \"You are a SQL query generator. Return ONLY the SQL query.\"},\n",
        "      {\"role\": \"user\", \"content\": \"What is the average salary by department?\"}\n",
        "    ],\n",
        "    \"temperature\": 0,\n",
        "    \"max_tokens\": 200\n",
        "  }'\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57b0f7d2",
      "metadata": {
        "id": "57b0f7d2"
      },
      "outputs": [],
      "source": [
        "# Test your fine-tuned model\n",
        "import requests\n",
        "import os\n",
        "\n",
        "print(\"🧪 Testing your fine-tuned model...\")\n",
        "\n",
        "# Model URL (using model name from earlier)\n",
        "url = \"https://api.fireworks.ai/inference/v1/chat/completions\"\n",
        "\n",
        "# Test questions\n",
        "test_questions = [\n",
        "    \"What is the average salary by department?\",\n",
        "    \"How many employees are in each department?\",\n",
        "    \"Who are the top 3 highest paid employees?\"\n",
        "]\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "print(f\"🎯 Testing model: {model_path}\")\n",
        "print(\"⏳ Note: Model must be deployed first!\")\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\n📋 Test {i}: {question}\")\n",
        "\n",
        "    data = {\n",
        "        \"model\": model_path,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a SQL query generator. Return ONLY the SQL query.\"},\n",
        "            {\"role\": \"user\", \"content\": question}\n",
        "        ],\n",
        "        \"temperature\": 0,\n",
        "        \"max_tokens\": 200\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=data)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        result = response.json()\n",
        "        sql_query = result['choices'][0]['message']['content'].strip()\n",
        "\n",
        "        print(f\"🔧 Generated SQL: {sql_query}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"❌ Request failed: {e}\")\n",
        "        if hasattr(e, 'response') and e.response is not None:\n",
        "            print(f\"Response: {e.response.text}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n✅ Testing complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cfe33a7",
      "metadata": {
        "id": "6cfe33a7"
      },
      "source": [
        "# 🎉 Summary\n",
        "\n",
        "Congratulations! You've completed the full Fireworks AI fine-tuning workflow.\n",
        "\n",
        "## 📋 What You Accomplished\n",
        "\n",
        "1. ✅ **Setup**: Installed and authenticated with Fireworks CLI\n",
        "2. ✅ **Data Prep**: Loaded Spider dataset and converted to Chat Completions format  \n",
        "3. ✅ **Upload**: Created dataset in Fireworks using `firectl create dataset`\n",
        "4. ✅ **Fine-tune**: Started training job with `firectl create supervised-fine-tuning-job`\n",
        "5. ✅ **Monitor**: Checked job status with `firectl get supervised-fine-tuning-job`\n",
        "6. ✅ **Deploy**: Deployed model with `firectl create deployment`\n",
        "7. ✅ **Test**: Queried your custom Text2SQL model\n",
        "\n",
        "## 🔧 Key Commands to Remember\n",
        "\n",
        "```bash\n",
        "# Core workflow\n",
        "firectl create dataset NAME ./data.jsonl\n",
        "firectl create supervised-fine-tuning-job --dataset NAME --output-model MODEL\n",
        "firectl create deployment accounts/ACCOUNT/models/MODEL --enable-addons\n",
        "\n",
        "# Monitoring  \n",
        "firectl list supervised-fine-tuning-jobs\n",
        "firectl get supervised-fine-tuning-job JOB_ID\n",
        "firectl list deployments\n",
        "firectl get deployment DEPLOYMENT_ID\n",
        "```\n",
        "\n",
        "## 🚀 Next Steps\n",
        "\n",
        "- Try different base models (`qwen2p5-coder-7b`, `llama-v3p1-8b-instruct`)\n",
        "- Experiment with more training data (use the full 7k dataset)\n",
        "- Adjust hyperparameters (`--epochs`, `--learning-rate`)\n",
        "- Deploy multiple models for A/B testing\n",
        "\n",
        "## 📚 Resources\n",
        "\n",
        "- [Fireworks Fine-tuning Docs](https://docs.fireworks.ai/fine-tuning/fine-tuning)\n",
        "- [firectl CLI Reference](https://docs.fireworks.ai/tools-sdks/firectl/firectl)\n",
        "- [Chat Completions Format](https://docs.fireworks.ai/guides/querying-text-models)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e198c282",
      "metadata": {
        "id": "e198c282"
      },
      "source": [
        "# Standalone Duck DB Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mWoerO2UWqXm",
      "metadata": {
        "id": "mWoerO2UWqXm"
      },
      "outputs": [],
      "source": [
        "#! pip install duckdb\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from datetime import datetime, date\n",
        "\n",
        "# Create a demo DuckDB database\n",
        "def create_demo_database():\n",
        "    \"\"\"Create a demo database with sample data using DuckDB\"\"\"\n",
        "    conn = duckdb.connect(':memory:')  # In-memory database for demo\n",
        "\n",
        "    # Create tables\n",
        "    conn.execute('''\n",
        "        CREATE TABLE employees (\n",
        "            id INTEGER PRIMARY KEY,\n",
        "            name VARCHAR NOT NULL,\n",
        "            department VARCHAR NOT NULL,\n",
        "            salary DOUBLE NOT NULL,\n",
        "            hire_date DATE NOT NULL\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    conn.execute('''\n",
        "        CREATE TABLE departments (\n",
        "            id INTEGER PRIMARY KEY,\n",
        "            name VARCHAR NOT NULL,\n",
        "            location VARCHAR NOT NULL\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    # Insert sample data\n",
        "    employees_data = [\n",
        "        (1, 'Alice Johnson', 'Engineering', 85000, '2022-01-15'),\n",
        "        (2, 'Bob Smith', 'Marketing', 72000, '2021-08-20'),\n",
        "        (3, 'Carol Davis', 'Engineering', 92000, '2020-03-10'),\n",
        "        (4, 'David Wilson', 'Sales', 68000, '2022-11-05'),\n",
        "        (5, 'Eva Brown', 'Marketing', 75000, '2021-12-01'),\n",
        "        (6, 'Frank Miller', 'Engineering', 88000, '2020-07-22'),\n",
        "        (7, 'Grace Lee', 'Sales', 72000, '2022-05-18'),\n",
        "        (8, 'Henry Taylor', 'HR', 65000, '2021-09-30')\n",
        "    ]\n",
        "\n",
        "    departments_data = [\n",
        "        (1, 'Engineering', 'San Francisco'),\n",
        "        (2, 'Marketing', 'New York'),\n",
        "        (3, 'Sales', 'Chicago'),\n",
        "        (4, 'HR', 'Austin')\n",
        "    ]\n",
        "\n",
        "    conn.executemany('INSERT INTO employees VALUES (?, ?, ?, ?, ?)', employees_data)\n",
        "    conn.executemany('INSERT INTO departments VALUES (?, ?, ?)', departments_data)\n",
        "\n",
        "    return conn\n",
        "\n",
        "# Create the demo database\n",
        "print(\"Creating demo database with DuckDB...\")\n",
        "db_conn = create_demo_database()\n",
        "\n",
        "# Show the data\n",
        "print(\"\\nSample data:\")\n",
        "print(\"Employees:\")\n",
        "employees_df = db_conn.execute(\"SELECT * FROM employees\").df()\n",
        "print(employees_df)\n",
        "\n",
        "print(\"\\nDepartments:\")\n",
        "departments_df = db_conn.execute(\"SELECT * FROM departments\").df()\n",
        "print(departments_df)\n",
        "\n",
        "# Get the schema for the API\n",
        "schema_info = db_conn.execute(\"DESCRIBE employees\").df()\n",
        "schema = \"CREATE TABLE employees (\\n\"\n",
        "for _, row in schema_info.iterrows():\n",
        "    schema += f\"  {row['column_name']} {row['column_type']},\\n\"\n",
        "schema = schema.rstrip(',\\n') + \"\\n);\\n\\n\"\n",
        "\n",
        "schema_info = db_conn.execute(\"DESCRIBE departments\").df()\n",
        "schema += \"CREATE TABLE departments (\\n\"\n",
        "for _, row in schema_info.iterrows():\n",
        "    schema += f\"  {row['column_name']} {row['column_type']},\\n\"\n",
        "schema = schema.rstrip(',\\n') + \"\\n);\"\n",
        "\n",
        "print(f\"\\nDatabase Schema:\")\n",
        "print(schema)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nTMW9U8uWrZv",
      "metadata": {
        "id": "nTMW9U8uWrZv"
      },
      "outputs": [],
      "source": [
        "# Fireworks Base URL\n",
        "import re\n",
        "url = \"https://api.fireworks.ai/inference/v1/chat/completions\"\n",
        "\n",
        "# The latest fine-tune you created\n",
        "model = model_path\n",
        "\n",
        "\n",
        "### These are just examples for demo purposes. Your account won't have these exact deployments unless you create them.\n",
        "# Model URL - change to your latest model you just created. This one I created earlier.\n",
        "# qwen2p5-coder-32b-instruct\n",
        "base_qc32b = \"accounts/fireworks/models/qwen2p5-32b-instruct#accounts/pyroworks/deployments/l5nzg8f2\" # base model\n",
        "ft_qc32b = \"accounts/pyroworks/models/spider-sql-sft20250722-115217\" # fine-tuned variant\n",
        "\n",
        "# qwen2p5-coder-7b\n",
        "base_qc7b = \"accounts/fireworks/models/qwen2p5-coder-7b-instruct#accounts/pyroworks/deployments/tqn20ka9\" # base model\n",
        "ft_qc7b = \"accounts/pyroworks/models/spider-sql-finetuned\" # fine-tuned variant\n",
        "model = ft_qc7b\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# Example questions to test\n",
        "questions = [\n",
        "    \"What is the average salary by department?\",\n",
        "    \"How many employees are in each department?\",\n",
        "    \"Who are the top 3 highest paid employees?\",\n",
        "    \"What is the total salary budget for Engineering?\",\n",
        "    \"What location has the most employees?\",\n",
        "    \"Who is the most tenured employee in Marketing?\",\n",
        "    \"Who is the most tenured employee in Marketing and where do they live?\",\n",
        "    \"Where does Eva Brown live and who does she work with?\",\n",
        "    \"Which employees started the same year together?\",\n",
        "    \"Which two employees started within the fewest days of each other?\",\n",
        "    \"Does engineering or marketing have more people?\"\n",
        "]\n",
        "\n",
        "# The fine-tuned 7b variant does better on the compound queries\n",
        "\n",
        "total_correct = 0\n",
        "for question in questions:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Prepare the chat messages\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"\"\"You are a SQL query generator. Your task is to convert natural language questions into valid SQL queries.\n",
        "\n",
        "                Rules:\n",
        "                - Return ONLY the SQL query\n",
        "                - No explanations or comments\n",
        "                - No markdown code blocks or formatting\n",
        "                - No references to examples, repositories, or documentation\n",
        "                - No prefacing text like \"Here's the query:\" or \"The SQL is:\"\n",
        "\n",
        "                Just return the raw SQL query.\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Database schema:\\n{schema}\\n\\nQuestion: {question}\"\n",
        "            }\n",
        "        ],\n",
        "        \"temperature\": 0,\n",
        "        \"max_tokens\": 500\n",
        "    }\n",
        "\n",
        "    # Make the request\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=data)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse the response\n",
        "        result = response.json()\n",
        "        sql_query = result['choices'][0]['message']['content'].strip()\n",
        "\n",
        "        print(\"Generated SQL:\")\n",
        "        print(sql_query)\n",
        "\n",
        "        # Execute the query on our demo database\n",
        "        try:\n",
        "            result_df = db_conn.execute(sql_query).df()\n",
        "            print(\"\\nQuery Result:\")\n",
        "            print(result_df)\n",
        "            total_correct += 1\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError executing query: {e}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error making request: {e}\")\n",
        "        if hasattr(e, 'response') and e.response is not None:\n",
        "            print(f\"Response: {e.response.text}\")\n",
        "\n",
        "\n",
        "# Clean up\n",
        "db_conn.close()\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Demo completed!\")\n",
        "\n",
        "model_name = re.search(r\"models/([^#]+)\", model).group(1)\n",
        "print(f\" {model_name} completion percentage: {total_correct / len(questions) * 100:.2f}%\")\n",
        "\n",
        "data = {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2NQoO0Qe7Kfo"
      },
      "id": "2NQoO0Qe7Kfo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}